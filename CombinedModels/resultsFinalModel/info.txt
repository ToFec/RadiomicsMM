./CombinedModels/resultsFinalModel/
mean tesetaccuracy: 0.787646244810668 +/- NA
0.787646244810668
############################
############################
############################
Model Fold 1
Call:
coxph(formula = as.formula(self$getFormulaString()), data = trainData)

  n= 493, number of events= 66 
   (24 observations deleted due to missingness)

                                coef exp(coef) se(coef)      z Pr(>|z|)    
wavelet.LLH_firstorder_Range  0.3827    1.4663   0.1029  3.719 0.000200 ***
sysWaehrend11                 0.9238    2.5189   0.2720  3.396 0.000683 ***
gender1                      -1.1453    0.3181   0.2571 -4.454 8.43e-06 ***
Max.Gy.                      -0.2187    0.8036   0.1455 -1.503 0.132883    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

                             exp(coef) exp(-coef) lower .95 upper .95
wavelet.LLH_firstorder_Range    1.4663      0.682    1.1984    1.7939
sysWaehrend11                   2.5189      0.397    1.4780    4.2929
gender1                         0.3181      3.144    0.1922    0.5266
Max.Gy.                         0.8036      1.244    0.6042    1.0688

Concordance= 0.788  (se = 0.024 )
Likelihood ratio test= 54.92  on 4 df,   p=3e-11
Wald test            = 56.46  on 4 df,   p=2e-11
Score (logrank) test = 62.28  on 4 df,   p=1e-12

Train accuracy: 0.787646244810668
Test accuracy: 0
Train accuracy inner loops: 0.780466214222485, 0.821205821205821, 0.815789473684211, 0.771132272371511, 0.754314178971713, 0.737770540742248, 0.782185107863605, 0.783464566929134, 0.83389808419132, 0.786780795469172, 0.749021526418787, 0.793954899744154, 0.737768910478834, 0.789155642658827, 0.794014991131201, 0.743052549562808, 0.803276676688961, 0.74435542607429, 0.773082587515577, 0.820932079968224, 0.817935658564889, 0.770812437311936, 0.796089550475515, 0.776570937653412, 0.828555910928731, 0.673072284312937, 0.78867853560682, 0.782693242586291, 0.773766546329723, 0.806492770059541
Test accuracy inner loops: 0.829545454545455, 0.650887573964497, 0.691831683168317, 0.638686131386861, 0.934595524956971, 0.849403122130395, 0.825174825174825, 0.836032388663968, 0.594622543950362, 0.793465577596266, 0.831401475237092, 0.756137479541735, 0.855065438681532, 0.829268292682927, 0.780632411067194, 0.795475530932595, 0.668269230769231, 0.686102236421725, 0.844444444444444, 0.644803229061554, 0.593939393939394, 0.805934242181235, 0.678642714570858, 0.769028871391076, 0.464454976303318, 0.828249336870027, 0.735492577597841, 0.87375415282392, 0.79140127388535, 0.798299845440495
